# ============================================================================
# CRIMEWISE AI GRADING SYSTEM - ENVIRONMENT VARIABLES
# ============================================================================
# Copy this file to .env for local development
# For Vercel deployment, add these variables in Settings > Environment Variables
# NEVER commit real .env file with actual secrets to GitHub

# ============================================================================
# DATABASE CONFIGURATION (REQUIRED)
# ============================================================================
# Option 1: Neon PostgreSQL (RECOMMENDED for 300+ concurrent submits)
# What: PostgreSQL connection string via Neon (free tier, unlimited connections)
# Get: From https://console.neon.tech → Create project → Copy connection string
# Format: postgresql://user:password@neon.tech/dbname?sslmode=require
DATABASE_URL=postgresql://user:password@ep-silent-cloud-a1234567.us-east-1.aws.neon.tech/crimewise?sslmode=require

# Option 2: SQLite Cloud (legacy, max 30 concurrent connections - not recommended for 300+ load)
# Format: sqlitecloud://ACCOUNT_ID.g5.sqlite.cloud:8860/DATABASE_NAME?apikey=YOUR_KEY
# DATABASE_URL=sqlitecloud://cxd2tnbwvk.g5.sqlite.cloud:8860/crimewise?apikey=euIjfRGcZnywBxr10nuXqdrk6BXamqJZvXRalZPVWVg

# ============================================================================
# GEMINI API KEYS FOR CHATBOT (REQUIRED)
# ============================================================================
# What: Single API key for student chatbot feature
# Where: Used by backend/routes/chatbot.js for Q&A chatbot
# Get: From https://aistudio.google.com/app/apikey
# Note: Separate from grading keys, not rotated
GEMINI_API_KEY=AIzaSyDEXAMPLE_YOUR_CHATBOT_KEY_HERE

# ============================================================================
# GEMINI API KEYS FOR AI GRADING (REQUIRED - All 6 keys)
# ============================================================================
# What: Six dedicated API keys for distributed AI grading (high concurrency)
# Where: Used by:
#   - backend/apiKeyManager.js (key rotation & rate limiting)
#   - backend/geminiGrader.js (AI model calls)
#   - backend/ai-worker.js (job processing)
# Get: From https://aistudio.google.com/app/apikey (create 6 separate keys)
# Purpose: Round-robin rotation to spread load (8 RPM per key = 48 total RPM)
# 
# Rate Limits Per Key:
#   - 60 RPM (requests per minute) - safe limit: 8 RPM
#   - 250 RPD (requests per day)
#   - With 6 keys: 48 RPM total capacity (safely handles 250-300 concurrent students)
#
GEMINI_API_KEY_1=AIzaSyDEXAMPLE_KEY_1_HERE
GEMINI_API_KEY_2=AIzaSyDEXAMPLE_KEY_2_HERE
GEMINI_API_KEY_3=AIzaSyDEXAMPLE_KEY_3_HERE
GEMINI_API_KEY_4=AIzaSyDEXAMPLE_KEY_4_HERE
GEMINI_API_KEY_5=AIzaSyDEXAMPLE_KEY_5_HERE
GEMINI_API_KEY_6=AIzaSyDEXAMPLE_KEY_6_HERE


# ============================================================================
# AI WORKER CONFIGURATION (OPTIONAL - Defaults provided)
# ============================================================================

# What: Number of AI grading jobs to process concurrently
# Where: Used by backend/ai-worker.js
# Default: 6 (one worker per API key for optimal parallelism)
# Safe range: 1-6 (higher may exceed rate limits)
AI_WORKER_CONCURRENCY=6

# What: How often (in ms) the worker polls database for pending jobs
# Where: Used by backend/ai-worker.js
# Default: 2000 (check every 2 seconds)
# Recommended: 2000-5000ms
AI_WORKER_POLL_MS=2000

# What: Maximum times a failed job will be retried before marking error
# Where: Used by backend/ai-worker.js
# Default: 3 (retry up to 3 times with exponential backoff)
# Range: 1-5
AI_WORKER_MAX_RETRIES=3

# ============================================================================
# APPLICATION ENVIRONMENT (OPTIONAL)
# ============================================================================

# What: Environment name for logging and error handling
# Where: Used by backend/index.js for CORS and error responses
# Values: 'development' (local), 'production' (Vercel)
NODE_ENV=development

# What: Server port for local development (Vercel auto-assigns 3000)
# Where: Used by backend/index.js
# Default: 5000
# Note: Not used on Vercel (serverless), only for local testing
PORT=5000

# ============================================================================
# SETUP INSTRUCTIONS
# ============================================================================
#
# LOCAL DEVELOPMENT:
#   1. Copy .env.example to .env
#   2. Fill in DATABASE_URL and all GEMINI_API_KEY_* values
#   3. Run: npm install && npm start
#   4. Server starts on http://localhost:5000
#   5. AI worker auto-starts and processes pending jobs
#
# VERCEL DEPLOYMENT:
#   1. Go to Vercel Dashboard > Your Project > Settings
#   2. Click "Environment Variables"
#   3. Add each variable below with your actual values:
#      ✓ DATABASE_URL (your SQLite Cloud connection)
#      ✓ GEMINI_API_KEY (chatbot key)
#      ✓ GEMINI_API_KEY_1 through GEMINI_API_KEY_6 (grading keys)
#      ✓ AI_WORKER_CONCURRENCY (optional, use 6)
#      ✓ AI_WORKER_POLL_MS (optional, use 2000)
#      ✓ AI_WORKER_MAX_RETRIES (optional, use 3)
#   4. Backend automatically redeploys when env vars change
#   5. Frontend uses relative API path /api (no secrets needed)
#
# ============================================================================
# MONITORING ENDPOINTS (Check in deployed app)
# ============================================================================
#
# Check API Key Health:
#   GET https://your-backend.vercel.app/api/monitor/api-keys
#   Shows: Number of loaded keys, total RPM capacity, usage stats
#
# Check AI Worker Status:
#   GET https://your-backend.vercel.app/api/monitor/ai-worker
#   Shows: Pending jobs, processing jobs, completed, errors, configuration
#
# Check Grades by API Key:
#   GET https://your-backend.vercel.app/api/monitor/grades-by-key
#   Shows: How many grades processed by each of the 6 keys (coming soon)
#
# ============================================================================
# TROUBLESHOOTING
# ============================================================================
#
# "No API keys configured" error:
#   → Check all GEMINI_API_KEY_1..6 are set in Vercel
#   → Verify keys are valid in Google AI Studio
#   → Check billing is enabled on Google Cloud project
#
# "AI grading takes too long" (stuck jobs):
#   → Check /api/monitor/ai-worker for error counts
#   → Verify all 6 keys are loaded via /api/monitor/api-keys
#   → Check if keys hit daily quota (250 RPD limit)
#
# "Database connection failed":
#   → Verify DATABASE_URL format matches sqlitecloud://... pattern
#   → Check SQLite Cloud dashboard shows active connection
#   → Ensure API key in connection string is current (may expire)
#
# ============================================================================
#   - 6 keys × 8 RPM = 48 RPM (safe margin below 60 RPM limit)
#   - Min delay: 7.5 seconds between requests enforced in ai-worker.js
#
# MONITORING:
#   - GET /api/monitor/api-keys → Check API key utilization
#   - GET /api/monitor/ai-worker → Check queue depth and configuration
#   - GET /health → Check backend health
#   - GET /test → Test connectivity
#
# DATABASE KEEP-ALIVE:
#   - GitHub Actions workflow runs every 10 hours (see .github/workflows/keep-alive.yml)
#   - Pings /api/cron/keep-alive to prevent 12-hour SQLite Cloud sleep
#
# ============================================================================
