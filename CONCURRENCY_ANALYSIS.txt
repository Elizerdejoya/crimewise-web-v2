================================================================================
AI GRADING CONCURRENCY ANALYSIS
================================================================================

๐ CURRENT CONCURRENCY SETTING:
================================================================================

Current Value: 1 (DEFAULT)
- Set in: backend/ai-worker.js line 15
- Environment var: AI_WORKER_CONCURRENCY
- Falls back to: 1 if not set

What this means:
- Only 1 AI grading job runs in parallel
- If 300 exams submitted, they queue up one-by-one
- Processing becomes linear (very slow)

FORMULA:
Processing Time = Total Jobs รท (Concurrency ร RPM Per Key)

Example with 300 jobs:
- Concurrency 1: 300 รท (1 ร 8) = 300 รท 8 = 37.5 minutes โ
- Concurrency 6: 300 รท (6 ร 8) = 300 รท 48 = 6.25 minutes โ

================================================================================
CONCURRENCY CONSTRAINTS:
================================================================================

1. API KEYS AVAILABLE:
   - Have: 6 Gemini API keys (GEMINI_API_KEY_1 through GEMINI_API_KEY_6)
   - Max safe concurrency: 6 (one job per key)
   - Each key has 8 RPM limit

2. DATABASE CONNECTIONS:
   - PostgreSQL: Unlimited (Vercel managed)
   - Connection pool per worker: 10 max
   - 6 workers ร 10 connections = 60 total (safe)
   - NO BOTTLENECK

3. GEMINI API RATE LIMITS:
   - Per key: 10 RPM (we use 8 for safety)
   - Per key: 250 requests/day
   - With 6 keys: 60 RPM total, 1,500 requests/day
   - Safe margin: Using 8 instead of 10 RPM

4. VERCEL SERVERLESS LIMITS:
   - Concurrent executions: Depends on plan (typically 1,000+)
   - Memory per instance: 3GB default
   - Timeout: 60 seconds (background jobs handled separately)
   - NO BOTTLENECK for concurrency=6

================================================================================
SAFE CONCURRENCY LEVELS:
================================================================================

LEVEL 1: Concurrency = 1 (CURRENT)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ Pros:                                   โ
โ โ Safest option                        โ
โ โ Minimal database load                โ
โ โ Never hits API limits                โ
โ โ Good for low traffic                 โ
โ                                         โ
โ Cons:                                   โ
โ โ 300 jobs = 37.5 minutes             โ
โ โ Slow grading feedback                โ
โ โ Not suitable for concurrent exams    โ
โ                                         โ
โ Recommended for: Testing, low volume    โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

LEVEL 2: Concurrency = 3
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ Pros:                                   โ
โ โ Good balance                         โ
โ โ 300 jobs = 12.5 minutes             โ
โ โ Low database load                    โ
โ โ Safe with 3 API keys                 โ
โ                                         โ
โ Cons:                                   โ
โ โ๏ธ  Only uses 3 of 6 API keys          โ
โ โ๏ธ  Not optimal for 300 concurrent     โ
โ                                         โ
โ Recommended for: Medium volume          โ
โ If you only have 3 API keys configured  โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

LEVEL 3: Concurrency = 6 (RECOMMENDED โ)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ Pros:                                   โ
โ โ Uses all 6 API keys efficiently      โ
โ โ 300 jobs = 6.25 minutes             โ
โ โ Optimal for 300 concurrent          โ
โ โ Rate: 48 RPM (well under limit)     โ
โ โ Database connections: 60 (safe)     โ
โ                                         โ
โ Cons:                                   โ
โ โ๏ธ  Slightly higher load                โ
โ โ๏ธ  6 concurrent API calls              โ
โ                                         โ
โ Recommended for: Production, 300 concat โ
โ THIS IS THE SAFE MAXIMUM FOR 6 KEYS    โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

LEVEL 4: Concurrency = 8+ (NOT RECOMMENDED โ)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ Cons:                                   โ
โ โ Only have 6 API keys                 โ
โ โ Jobs would queue waiting for keys    โ
โ โ No actual performance gain            โ
โ โ Wastes resources                      โ
โ                                         โ
โ Would need: 8+ API keys for benefit    โ
โ Current action: Skip this level         โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

================================================================================
RECOMMENDATION: Concurrency = 6 โ
================================================================================

Why 6 is SAFE:
1. Exactly matches number of API keys (1:1 mapping)
2. Rate limiting: 6 ร 8 RPM = 48 RPM (27% under Google's 60 RPM global limit)
3. Database: 6 ร 10 connections = 60 (well under PostgreSQL limit)
4. Processing: 300 jobs in ~6 minutes (acceptable)
5. Backpressure: Built-in retry logic prevents overload

How to Set:
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ Option 1: Set in .env                    โ
โ AI_WORKER_CONCURRENCY=6                 โ
โ                                          โ
โ Option 2: Set in Vercel Environment      โ
โ https://vercel.com/[project]/settings    โ
โ โ Environment Variables                  โ
โ โ Add: AI_WORKER_CONCURRENCY = 6        โ
โ                                          โ
โ Option 3: For local testing              โ
โ AI_WORKER_CONCURRENCY=6 node backend/... โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

================================================================================
PERFORMANCE COMPARISON:
================================================================================

                    Concurrency=1   Concurrency=3   Concurrency=6
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
300 submissions     37.5 minutes    12.5 minutes    6.25 minutes
per API call        ~30 sec         ~30 sec         ~30 sec
parallel jobs       1               3               6
database load       โ Low          โ๏ธ Medium       โ Medium
api rate            8 RPM           24 RPM          48 RPM
safety margin       92%             60%             20%
recommendation      โ Too slow      โ๏ธ Middle       โ BEST

================================================================================
VERIFICATION COMMANDS:
================================================================================

Check current concurrency in code:
$ grep -n "MAX_CONCURRENCY" backend/ai-worker.js
Output: const MAX_CONCURRENCY = Number(process.env.AI_WORKER_CONCURRENCY || 1);

Check if environment variable is set:
$ echo $AI_WORKER_CONCURRENCY
Output: (empty = using default 1)

In Vercel logs, you'll see:
[AI-WORKER] Max concurrency: 6 (one per API key)
[AI-WORKER] Rate limit: 8 RPM per key = 48 total RPM

================================================================================
ACTION ITEMS:
================================================================================

1. โ RECOMMENDED: Set AI_WORKER_CONCURRENCY=6
   - Add to .env file
   - Redeploy to Vercel
   - Restart ai-worker service
   
2. โ OPTIONAL: Increase API keys
   - Add GEMINI_API_KEY_7 and GEMINI_API_KEY_8
   - Would allow concurrency=8+ safely
   - Each key = +8 RPM capacity
   
3. โ OPTIONAL: Adjust RPM per key
   - Current: 8 RPM (safe)
   - Could increase to: 9 or 10 RPM
   - Would increase total capacity to 54-60 RPM

================================================================================
SUMMARY:
================================================================================

Current Concurrency:  1 (DEFAULT - very slow for 300 concurrent)
Safe Concurrency:     6 (RECOMMENDED - optimized for 6 API keys)
Max Concurrency:      6 (limited by number of API keys)

Effect of changing to 6:
- 300 submissions will be graded in ~6.25 minutes instead of 37.5 minutes
- 6x speed improvement
- Still safe: 48 RPM / 60 RPM limit = 20% margin

Next Steps: Set AI_WORKER_CONCURRENCY=6 in environment!

================================================================================
